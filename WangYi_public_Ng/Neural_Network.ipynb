{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss (error) function:\n",
    "$$L(\\widehat{y},y)=-(ylog(\\widehat{y})+(1-y)log(1-\\widehat{y}))$$\n",
    "#### Cost function:\n",
    "$$J(w,b)=\\frac{1}{m}\\sum_{i=1}^{m}L(\\widehat{y}^{(i)},y^{(i)})=-\\frac{1}{m}\\sum_{i=1}^{m}[{y}^{(i)}log(\\widehat{y}^{(i)})+(1-{y}^{(i)})log(1-\\widehat{y}^{(i)})]$$\n",
    "#### Gradient Descent:\n",
    "To find $w, b$ that minimize $J(w,b)$, we use gradient descent method:\n",
    "$$w:=w-\\alpha \\cdot \\frac{\\partial J(w,b)}{\\partial w}$$\n",
    "$$b:=b-\\alpha \\cdot \\frac{\\partial J(w,b)}{\\partial b}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions:\n",
    "Activation functions characteristic of non-linear. Here f(z) refers to the activation functions. We can choose various activation function in neural network.\n",
    "1. Tanh(z):\n",
    "$$tanh(z)=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$$\n",
    "and its derivative is\n",
    "$$f'(z)=1-(f(z))^2$$\n",
    "Tanh(z) is often used in hidden layer.\n",
    "\n",
    "2. Sigmoid(z):\n",
    "$$Sigmoid(z)=\\frac{1}{1+exp(-z)}$$\n",
    "and its derivative is\n",
    "$$f'(z)=f(z)(1-f(z))$$\n",
    "Never use this except you are doing binary classification.\n",
    "\n",
    "3. ReLU:\n",
    "$$ReLU(z)=max(0,z)$$\n",
    "$$f'(z) = \\left\\{ \\begin{array}{ll}\n",
    "1 & \\textrm{if $z>0$}\\\\\n",
    "0 & \\textrm{if $z<0$}\\\\\n",
    "undefiend & \\textrm{if $z=0$}\n",
    "\\end{array} \\right .$$\n",
    "But we often include z=0 into region z>0, so \n",
    "$$f'(z) = \\left\\{ \\begin{array}{ll}\n",
    "1 & \\textrm{if $z>0$}\\\\\n",
    "0 & \\textrm{if $z\\le0$}\\\\\n",
    "\\end{array} \\right .$$\n",
    "Faster converge velocity than others and trimmed larger than zero. Usually default.\n",
    "\n",
    "3. Leaky ReLU\n",
    "Similar with ReLU, but not exactly equal to zero when z<0\n",
    "$$ReLU(z)=max(0.01z,z)$$\n",
    "$$f'(z) = \\left\\{ \\begin{array}{ll}\n",
    "1 & \\textrm{if $z>0$}\\\\\n",
    "0.01 & \\textrm{if $z<0$}\\\\\n",
    "undefiend & \\textrm{if $z=0$}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
